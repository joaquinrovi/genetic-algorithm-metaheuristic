{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "from model.model import Model\n",
    "from axis.axis import Axis\n",
    "from output.values_goals import ValuesGoals\n",
    "from data_processing.flujo_down import DownBase\n",
    "from data_processing.flujo_mid import FlujoMid\n",
    "from data_processing.flujo_union import DataProcessing\n",
    "from data_processing.flujo_caja_utils import union_flujos, union_flujos_2, get_vpn_calculado\n",
    "from utils.databricks_hivemetastore import DatabricksHive\n",
    "from utils.logger import Logger\n",
    "from utils.general_utils import read_json, auto_cast_df, get_configuration, get_configuration_model, try_float, check_units, get_run_params, spark_cast, save_table_real, save_capex_debt, get_colombian_time, import_model_results, save_types_union, save_db_name_csv\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=Warning)\n",
    "\n",
    "logger = Logger(__name__).get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de funciones\n",
    "def measure_time(task_name, func, *args):\n",
    "    \"\"\"\n",
    "    Executes a function, measures its execution time, and logs the start, end, and elapsed time.\n",
    "\n",
    "    :param task_name: Name or description of the task being measured.\n",
    "    :type task_name: str\n",
    "    :param func: The function that needs its execution time to be measured.\n",
    "    :type func: function\n",
    "    :param *args: Variable length argument list of the function's parameters.\n",
    "    :type *args: tuple\n",
    "    :return: Returns what the input function returns.\n",
    "    :rtype: varies based on the function\n",
    "    \"\"\"\n",
    "    logger.info(f\"{task_name} successfully started\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    result = func(*args)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = (end_time - start_time) / 60\n",
    "    logger.info(f\"{task_name} successfully finished, {elapsed_time:.2f} minutes\")\n",
    "\n",
    "    return result\n",
    "\n",
    "def process_fc_up_be_isa_down(data_processing):\n",
    "    \"\"\"\n",
    "    Processes the given data and resets its index.\n",
    "\n",
    "    :param data_processing: An instance of a class with the fc_up_be_isa_down() method.\n",
    "    :type data_processing: Object\n",
    "    :return: DataFrame with reset index.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    df,df2 = data_processing.fc_up_be_isa_down()\n",
    "    return df.reset_index(drop=True),df2\n",
    "\n",
    "def run_model(model_config, params, df_union, df_down, df_mid, initial=False):\n",
    "    \"\"\"\n",
    "    Runs a machine learning model using the provided configurations and data.\n",
    "\n",
    "    :param model_config: Configuration parameters for the Model.\n",
    "    :type model_config: dict\n",
    "    :param params: Additional parameters for the model.\n",
    "    :type params: dict\n",
    "    :param df_union: DataFrame containing union data.\n",
    "    :type df_union: pd.DataFrame\n",
    "    :param df_down: DataFrame containing down base data.\n",
    "    :type df_down: pd.DataFrame\n",
    "    :param df_mid: DataFrame containing mid base data.\n",
    "    :type df_mid: pd.DataFrame\n",
    "    :param initial: bool to tell if this is a configuration run or a normal run\n",
    "    :type initial: bool\n",
    "    :return: Results and parameters of the run model.\n",
    "    :rtype: tuple(pd.DataFrame, pd.DataFrame)\n",
    "    \"\"\"\n",
    "    model = Model(model_config, params, df_union, df_down, df_mid, initial)\n",
    "    return model.run_generations()\n",
    "\n",
    "def get_down_base(df_model_results, config, api_config,input_up):\n",
    "    \"\"\"\n",
    "    Generates a down base DataFrame based on model results and configuration.\n",
    "\n",
    "    :param df_model_results: DataFrame containing results of a model run.\n",
    "    :type df_model_results: pd.DataFrame\n",
    "    :param config: Configuration parameters for DownBase.\n",
    "    :type config: dict\n",
    "    :param api_config: Configuration parameters from powerBI\n",
    "    :type api_config: dict\n",
    "    :return: DataFrame representing the down base with set column values.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    base = DownBase(df_model_results, config, api_config,input_up)\n",
    "    df = base.get_base(False)\n",
    "    df.loc[:, \"TIPO_FLUJO_CAJA_FLAG\"] = \"REAL\"\n",
    "    return df\n",
    "\n",
    "def get_mid_base(df_model_results, config, api_config,model_results):\n",
    "    \"\"\"\n",
    "    Generates a mid base DataFrame based on model results and configuration.\n",
    "\n",
    "    :param df_model_results: DataFrame containing results of a model run.\n",
    "    :type df_model_results: pd.DataFrame\n",
    "    :param config: Configuration parameters for MidBase.\n",
    "    :type config: dict\n",
    "    :param api_config: Configuration parameters from powerBI\n",
    "    :type api_config: dict\n",
    "    :return: DataFrame representing the mid base with set column values.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    base = FlujoMid(df_model_results, config, api_config,model_results)\n",
    "    df = base.calculate_mid()\n",
    "    df.loc[:, \"TIPO_FLUJO_CAJA_FLAG\"] = \"REAL\"\n",
    "    return df\n",
    "\n",
    "def get_down_base(df_model_results, config, api_config):\n",
    "    \"\"\"\n",
    "    Generates a down base DataFrame based on model results and configuration.\n",
    "\n",
    "    :param df_model_results: DataFrame containing results of a model run.\n",
    "    :type df_model_results: pd.DataFrame\n",
    "    :param config: Configuration parameters for DownBase.\n",
    "    :type config: dict\n",
    "    :param api_config: Configuration parameters from powerBI\n",
    "    :type api_config: dict\n",
    "    :return: DataFrame representing the down base with set column values.\n",
    "    :rtype: pd.DataFrame\n",
    "    \"\"\"\n",
    "    base = DownBase(df_model_results, config, api_config)\n",
    "    df = base.get_base(False)\n",
    "    df.loc[:, \"TIPO_FLUJO_CAJA_FLAG\"] = \"REAL\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_config = read_json(\"config/main_config.json\")\n",
    "data_source_config = read_json(\"config/data_source_config.json\")\n",
    "model_config = get_configuration_model(main_config[\"config_path\"], \"config/model_config.json\")\n",
    "total_caja_config = get_configuration(main_config[\"config_path\"], \"config/fuente_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0,30,20,2.5,40,3.17,40,13,0,30,0,6.75,0,647.5,0,2001,0,230,0,2,0,2,0,2,0,\n",
    "3000,0,21,1,100,100,100,100,100,50,50,0.5,0.5,1,1,1,0,0,0,\"momento1\"]\n",
    "params_encabezado = [\n",
    "\"vpn_weight\",\n",
    "\"vpn_goal\",\n",
    "\"deuda_bruta_weight\",\n",
    "\"deuda_bruta_ratio\",\n",
    "\"trans_nacion_weight\",\n",
    "\"trans_nacion_min\",\n",
    "\"ebitda_weight\",\n",
    "\"ebitda_min\",\n",
    "\"low_emissions_weight\",\n",
    "\"low_emissions_min\",\n",
    "\"emisiones_netas_co2_alcance_1_y_2_weight\",\n",
    "\"emisiones_netas_co2_alcance_1_y_2_actual\",\n",
    "\"neutralidad_agua_weight\",\n",
    "\"neutralidad_agua_actual\",\n",
    "\"mwh_weight\",\n",
    "\"mwh_goal\",\n",
    "\"not_oil_jobs_weight\",\n",
    "\"not_oil_jobs_goal\",\n",
    "\"students_weight\",\n",
    "\"students_goal\",\n",
    "\"natural_gas_weight\",\n",
    "\"natural_gas_actual\",\n",
    "\"agua_potable_weight\",\n",
    "\"agua_potable_actual\",\n",
    "\"km_weight\",\n",
    "\"km_actual\",\n",
    "\"cti_weight\",\n",
    "\"cti_min\",\n",
    "\"val_curva_crudo\",\n",
    "\"val_sensi_precio_crudo\",\n",
    "\"val_sensi_precio_gas\",\n",
    "\"val_sensi_precio_Hidro\",\n",
    "\"val_delta_energia\",\n",
    "\"val_sensi_precio_co2\",\n",
    "\"generations\",\n",
    "\"sol_per_pop\",\n",
    "\"mutation_ind\",\n",
    "\"mutation_gen\",\n",
    "\"vpn_zero_restriction\",\n",
    "\"be_restriction\",\n",
    "\"phase_restriction\",\n",
    "\"cash_flow_restriction\",\n",
    "\"gas_demanda_nacion\",\n",
    "\"transporte_offshore\",\n",
    "\"momento\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dic = dict(zip(params_encabezado, params))\n",
    "params_to_float = params_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_inital_base\n",
    "dfs_dict_result = {}\n",
    "data_processing = DataProcessing(total_caja_config, params_to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flujo_union, df_flujo_caja_up = measure_time(\n",
    "    \"fc_up_be_isa_down\", process_fc_up_be_isa_down, data_processing\n",
    ")\n",
    "\n",
    "flujo_union = get_vpn_calculado(flujo_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flujo_union[\"MATRICULA_DIGITAL\"] = flujo_union[\"MATRICULA_DIGITAL\"].astype(str)\n",
    "flujo_union[\"DEPENDENCIAS\"] = flujo_union[\"DEPENDENCIAS\"].astype(str)\n",
    "flujo_union[\"EXCLUYENTES\"] = flujo_union[\"EXCLUYENTES\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    model_results,\n",
    "    model_fitness\n",
    ") = measure_time(\n",
    "    \"Model\",\n",
    "    run_model,\n",
    "    model_config,\n",
    "    params_to_float,\n",
    "    flujo_union,\n",
    "    None,\n",
    "    None,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.to_csv(\"output/model_results_240424.csv\", index=False,sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_union.to_csv(\"output/df_union_240424.csv\", index=False,sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flujo_down_real = measure_time(\n",
    "    \"DownBase\",\n",
    "    get_down_base,\n",
    "    model_results,\n",
    "    total_caja_config,\n",
    "    params_to_float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(model_config, #config_dict\n",
    "    params_to_float, #pb_parameters\n",
    "    flujo_union, #input_data\n",
    "    None, #down_data\n",
    "    None, #mid_data\n",
    "    True) #initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_projects.to_csv(\"output/df_projects_240424.csv\", index=False,sep = \";\")\n",
    "model.df_vpn_zero_projects.to_csv(\"output/df_vpn_zero_projects_240424.csv\", index=False,sep = \";\")\n",
    "model.df_mandatory_projects.to_csv(\"output/df_mandatory_projects_240424.csv\", index=False,sep = \";\")\n",
    "model.df_semi_mandatory.to_csv(\"output/df_semi_mandatory_240424.csv\", index=False,sep = \";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_projects[\"MATRICULA_DIGITAL\"] = model.df_projects[\"MATRICULA_DIGITAL\"].astype(str)\n",
    "model.df_projects[\"DEPENDENCIAS\"] = model.df_projects[\"DEPENDENCIAS\"].astype(str)\n",
    "model.df_projects[\"EXCLUYENTES\"] = model.df_projects[\"EXCLUYENTES\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_mandatory_projects[\"MATRICULA_DIGITAL\"].unique().tolist()+model.df_semi_mandatory[\"MATRICULA_DIGITAL\"].unique().tolist()+model.df_vpn_zero_projects[\"MATRICULA_DIGITAL\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyga_instance = model.init_pygad()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_projects(df):\n",
    "    \"\"\"\n",
    "    Selects projects based on their dependencies and exclusions.\n",
    "\n",
    "    This function takes a DataFrame containing project information as input and selects projects that can be executed considering their dependencies and exclusions.\n",
    "\n",
    "    :param df: DataFrame containing project information including 'Proyecto' (Project), 'Dependencias' (Dependencies), and 'Excluyentes' (Exclusions).\n",
    "    :type df: pandas.DataFrame\n",
    "\n",
    "    :return: List of projects that are available for selection based on their dependencies and exclusions.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    available_projects = []\n",
    "    selected_projects = set()\n",
    "    exclusive_projects = set()\n",
    "    for index, row in df.iterrows():\n",
    "        project = row['MATRICULA_DIGITAL']\n",
    "        dependencies = [dep.strip() for dep in row['DEPENDENCIAS'].split(',')]\n",
    "        if dependencies == ['NA']:\n",
    "            dependencies = []\n",
    "        exclusions = [ex.strip() for ex in row['EXCLUYENTES'].split(',')]\n",
    "        if exclusions == ['NA']:\n",
    "            exclusions = []\n",
    "\n",
    "        # Check if all dependencies are satisfied and the project is not excluded\n",
    "        if len(dependencies)+len(exclusions) >0:\n",
    "            if all(dep in selected_projects for dep in dependencies) and not any(ex in exclusive_projects for ex in exclusions):\n",
    "                available_projects.append(project)\n",
    "        else:\n",
    "            available_projects.append(project)\n",
    "\n",
    "        # Add the project to selected projects and update exclusions\n",
    "        selected_projects.add(project)\n",
    "        exclusive_projects.update(exclusions)\n",
    "    return available_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.df_projects[\"DEPENDENCIAS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_projects_random(df):\n",
    "    available_projects = []\n",
    "    selected_projects = set()\n",
    "    exclusive_projects = set()\n",
    "    \n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        project = row['MATRICULA_DIGITAL']\n",
    "        dependencies = [dep.strip() for dep in row['DEPENDENCIAS'].split(',')]\n",
    "        if dependencies == ['NA']:\n",
    "            dependencies = []\n",
    "        exclusions = [ex.strip() for ex in row['EXCLUYENTES'].split(',')]\n",
    "        if exclusions == ['NA']:\n",
    "            exclusions = []\n",
    "       \n",
    "        # Verificar si las dependencias están satisfechas.\n",
    "        if all(dep in selected_projects for dep in dependencies):\n",
    "            # Verificar si el proyecto no es excluido por cualquier otro proyecto.\n",
    "            excluded = False\n",
    "            for ex in exclusions:\n",
    "                if ex in selected_projects:\n",
    "                    excluded = True\n",
    "                    break\n",
    "            # Si no está excluido, añadir el proyecto a la lista de proyectos disponibles.\n",
    "            if not excluded:\n",
    "                available_projects.append(project)\n",
    "     \n",
    "        # Añadir el proyecto a los proyectos seleccionados y actualizar las exclusiones.\n",
    "        selected_projects.add(project)\n",
    "        exclusive_projects.update(exclusions)\n",
    "      \n",
    "        # Aleatorizar el orden para las exclusiones para la siguiente iteración.\n",
    "        exclusive_projects_list = list(exclusive_projects)\n",
    "        random.shuffle(exclusive_projects_list)\n",
    "        exclusive_projects = set(exclusive_projects_list)\n",
    "   \n",
    "    return available_projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'MATRICULA_DIGITAL': ['Proyecto B ETAPA 2', 'Proyecto A ETAPA 2', 'Proyecto A ETAPA 1', 'Proyecto C', 'Proyecto B ETAPA 1','Proyecto X','Proyecto Y','Proyecto Z','Proyecto AA','Proyecto AB'],\n",
    "    'DEPENDENCIAS': ['Proyecto B ETAPA 1, Proyecto C', 'Proyecto A ETAPA 1', '', '', 'Proyecto A ETAPA 2','','','','',''],\n",
    "    'EXCLUYENTES': ['', '', '', 'Proyecto A ETAPA 1, Proyecto A ETAPA 2', '','','','Proyecto AA, Proyecto AB','Proyecto Z, Proyecto AB','Proyecto Z, Proyecto AA'],\n",
    "}\n",
    " \n",
    "dataframe = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutaciones = [1,1,1,1,1,1,0,1,1,0]\n",
    "mutaciones_filtro = [True if mut == 1 else False for mut in mutaciones]\n",
    "mutaciones_filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_available = dataframe[\"MATRICULA_DIGITAL\"][[False if mut == 1 else True for mut in mutaciones]].tolist()\n",
    "not_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2 = dataframe[mutaciones_filtro]\n",
    "dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar proyectos con exclusiones \n",
    "\n",
    "available_projects = dataframe2[\"MATRICULA_DIGITAL\"][(dataframe2[\"EXCLUYENTES\"]==\"\")].tolist()\n",
    "lista_pro_exl = [proyecto for proyecto in dataframe2[\"MATRICULA_DIGITAL\"].unique().tolist() if proyecto not in available_projects]\n",
    "excluded_projects = []\n",
    "#excluded_projects = dataframe[\"MATRICULA_DIGITAL\"][[False if mut == 1 else True for mut in mutaciones]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 0\n",
    "n = len(lista_pro_exl)\n",
    "while len(lista_pro_exl) > 0:\n",
    "    i+=1\n",
    "    print(i)\n",
    "    if i>n:\n",
    "        break\n",
    "    df_trabajo = dataframe2[dataframe2[\"MATRICULA_DIGITAL\"].isin(lista_pro_exl)]\n",
    "    for index, row in df_trabajo.iterrows():\n",
    "        project = row['MATRICULA_DIGITAL']\n",
    "        print(\"proyecto que se esta evaluando \"+ str(project))\n",
    "        exclusions = [ex.strip() for ex in row['EXCLUYENTES'].split(',')]\n",
    "        \n",
    "        #Verificar si todas las exclusiones están en los proyectos seleccionados\n",
    "        es_aleatorio = False\n",
    "        lista_aleatorio = [project]        \n",
    "        for ex in exclusions:\n",
    "            if ex in lista_pro_exl_ori:\n",
    "                exclusiones_ex = [ex.strip() for ex in df_trabajo[\"EXCLUYENTES\"][df_trabajo[\"MATRICULA_DIGITAL\"]==ex].values[0].split(',')]\n",
    "                if project in exclusiones_ex:\n",
    "                    es_aleatorio = True\n",
    "                    lista_aleatorio.append(ex)\n",
    "        print(lista_aleatorio)\n",
    "        print(\"Es aleatorio \"+str(es_aleatorio))  \n",
    "        if es_aleatorio:\n",
    "            pro_sel_ale = random.choice(lista_aleatorio)\n",
    "            print(\"Proyecto seleccionado aleatoriamente \"+str(pro_sel_ale))\n",
    "            lista_pro_exl.remove(pro_sel_ale)\n",
    "            lista_aleatorio.remove(pro_sel_ale)\n",
    "            available_projects.append(pro_sel_ale)\n",
    "            excluded_projects = excluded_projects+lista_aleatorio\n",
    "            print(\"Proyectos excluidos \"+str(lista_aleatorio))\n",
    "            for pro in lista_aleatorio:\n",
    "                lista_pro_exl.remove(pro)\n",
    "            break\n",
    "        else:\n",
    "            if all (ex in available_projects + excluded_projects for ex in exclusions):\n",
    "                # Verificar si el proyecto no es excluido por cualquier otro proyecto.\n",
    "                excluded = False\n",
    "                for ex in exclusions:\n",
    "                    if ex in available_projects:\n",
    "                        excluded = True\n",
    "                        break\n",
    "                lista_pro_exl.remove(project)\n",
    "                if excluded:\n",
    "                    excluded_projects.append(project)\n",
    "                else:\n",
    "                    selected_projects.append(project)\n",
    "            else:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe3 = dataframe2[dataframe2[\"MATRICULA_DIGITAL\"].isin(available_projects)]\n",
    "dataframe3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_projects = dataframe3[dataframe3[\"DEPENDENCIAS\"] == \"\"][\"MATRICULA_DIGITAL\"].tolist()\n",
    "lista_pro_dep = [proyecto for proyecto in dataframe3[\"MATRICULA_DIGITAL\"].unique().tolist() if proyecto not in select_projects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "n = len(lista_pro_dep)\n",
    "while len(lista_pro_dep) > 0:\n",
    "    i+=1\n",
    "    if i>n:\n",
    "        break\n",
    "    df_trabajo = dataframe3[dataframe3[\"MATRICULA_DIGITAL\"].isin(lista_pro_dep)]\n",
    "    for index, row in df_trabajo.iterrows():\n",
    "        project = row['MATRICULA_DIGITAL']\n",
    "        dependencies = [dep.strip() for dep in row['DEPENDENCIAS'].split(',')]\n",
    "        if dependencies == ['NA']:\n",
    "            dependencies = []\n",
    "        # Verificar si las dependencias están satisfechas.\n",
    "        if all(dep in select_projects + excluded_projects for dep in dependencies):\n",
    "            if all(dep in select_projects for dep in dependencies):\n",
    "                select_projects.append(project)\n",
    "                lista_pro_dep.remove(project)\n",
    "            else:\n",
    "                if any(dep in excluded_projects for dep in dependencies):\n",
    "                    excluded_projects.append(project)\n",
    "                    lista_pro_dep.remove(project)\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulación del bucle como método"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede encapsular el bucle de selección de proyectos en una función para hacer el código más modular y reutilizable. Acá está el código modificado para que la selección de proyectos excluidos esté dentro de una función llamada seleccionar_proyectos_excluidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proyectos disponibles: ['Proyecto Z']\n",
      "Proyectos excluidos: ['Proyecto AA', 'Proyecto AB']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def seleccionar_proyectos_excluidos(mutants, df_projects):\n",
    "    \"\"\"\n",
    "    Selects projects considering their dependencies and exclusions.\n",
    "\n",
    "    This function takes a DataFrame containing project information as input and selects projects that can be executed considering \n",
    "    their dependencies and exclusions.\n",
    "    \n",
    "    :param mutant: np.array containing the portafolio to be checked\n",
    "    :type mutant: np.array\n",
    "    :param df_projects: df containing projects\n",
    "    :type df_projects: DataFrame\n",
    "\n",
    "    :return: Tuple containing lists of projects that are available and excluded for selection based on their dependencies and exclusions.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    available_projects = []\n",
    "    excluded_projects = []\n",
    "    lista_pro_exl_ori = df_projects[\"MATRICULA_DIGITAL\"].unique().tolist()\n",
    "    lista_pro_exl = lista_pro_exl_ori.copy()\n",
    "\n",
    "    for i in range(len(mutants)):\n",
    "        if mutants[i] == 1:\n",
    "            project = df_projects.loc[i, 'MATRICULA_DIGITAL']\n",
    "            exclusions = [ex.strip() for ex in df_projects.loc[i, 'EXCLUYENTES'].split(',')]\n",
    "\n",
    "            if all(ex in available_projects + excluded_projects for ex in exclusions):\n",
    "                excluded = False\n",
    "                for ex in exclusions:\n",
    "                    if ex in available_projects:\n",
    "                        excluded = True\n",
    "                        break\n",
    "                lista_pro_exl.remove(project)\n",
    "                if excluded:\n",
    "                    excluded_projects.append(project)\n",
    "                else:\n",
    "                    available_projects.append(project)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    i = 0\n",
    "    n = len(lista_pro_exl)\n",
    "    while len(lista_pro_exl) > 0:\n",
    "        i += 1\n",
    "        if i > n:\n",
    "            break\n",
    "        df_trabajo = df_projects[df_projects[\"MATRICULA_DIGITAL\"].isin(lista_pro_exl)]\n",
    "        for index, row in df_trabajo.iterrows():\n",
    "            project = row['MATRICULA_DIGITAL']\n",
    "            exclusions = [ex.strip() for ex in row['EXCLUYENTES'].split(',')]\n",
    "            \n",
    "            es_aleatorio = False\n",
    "            lista_aleatorio = [project]\n",
    "            for ex in exclusions:\n",
    "                if ex in lista_pro_exl_ori:\n",
    "                    exclusiones_ex = [ex.strip() for ex in df_trabajo[\"EXCLUYENTES\"][df_trabajo[\"MATRICULA_DIGITAL\"]==ex].values[0].split(',')]\n",
    "                    if project in exclusiones_ex:\n",
    "                        es_aleatorio = True\n",
    "                        lista_aleatorio.append(ex)\n",
    "            \n",
    "            if es_aleatorio:\n",
    "                pro_sel_ale = random.choice(lista_aleatorio)\n",
    "                lista_pro_exl.remove(pro_sel_ale)\n",
    "                lista_aleatorio.remove(pro_sel_ale)\n",
    "                available_projects.append(pro_sel_ale)\n",
    "                excluded_projects.extend(lista_aleatorio)\n",
    "                for pro in lista_aleatorio:\n",
    "                    lista_pro_exl.remove(pro)\n",
    "                break\n",
    "            else:\n",
    "                if all(ex in available_projects + excluded_projects for ex in exclusions):\n",
    "                    excluded = False\n",
    "                    for ex in exclusions:\n",
    "                        if ex in available_projects:\n",
    "                            excluded = True\n",
    "                            break\n",
    "                    lista_pro_exl.remove(project)\n",
    "                    if excluded:\n",
    "                        excluded_projects.append(project)\n",
    "                    else:\n",
    "                        available_projects.append(project)\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    return available_projects, excluded_projects\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = {\n",
    "    'MATRICULA_DIGITAL': ['Proyecto B ETAPA 2', 'Proyecto A ETAPA 2', 'Proyecto A ETAPA 1', 'Proyecto C', 'Proyecto B ETAPA 1','Proyecto X','Proyecto Y','Proyecto Z','Proyecto AA','Proyecto AB'],\n",
    "    'DEPENDENCIAS': ['Proyecto B ETAPA 1, Proyecto C', 'Proyecto A ETAPA 1', '', '', 'Proyecto A ETAPA 2','','','','',''],\n",
    "    'EXCLUYENTES': ['', '', '', 'Proyecto A ETAPA 1, Proyecto A ETAPA 2', '','','','Proyecto AA, Proyecto AB','Proyecto Z, Proyecto AB','Proyecto Z, Proyecto AA'],\n",
    "}\n",
    "\n",
    "df_projects = pd.DataFrame(data)\n",
    "mutants = [1,1,1,1,1,1,0,1,1,0]\n",
    "\n",
    "available_projects, excluded_projects = seleccionar_proyectos_excluidos(mutants, df_projects)\n",
    "print(\"Proyectos disponibles:\", available_projects)\n",
    "print(\"Proyectos excluidos:\", excluded_projects)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portafolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
